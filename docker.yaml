version: "3.8"

services:
  app:
    # Use the official TensorFlow image as the base
    image: tensorflow/tensorflow:2.15.0-gpu
    
    # Give your container a consistent name
    container_name: my_tf_app
    
    # Mounts the current folder into the /app directory in the container
    volumes:
      - .:/app
      
    # Sets the starting directory inside the container to /app
    working_dir: /app

    # CORRECTED: Combines setup and execution into one command.
    # The container will stay running as long as containerTest.py is running.
    command: sh -c "
    			pip install gdown &&
            echo 'Downloading dataset from Google Drive...' &&
            gdown 'https://drive.google.com/file/d/1w8T8aMhQjlx75vEjIdTK_zDwJPGzpkgy/view?usp=sharing' -O /app/stacking_blocks.zip &&
            echo 'Unzipping dataset...' &&
            unzip /app/stacking_blocks.zip -d /app/stacking_blocks &&
            rm /app/stacking_blocks.zip &&
            echo 'Starting application...'&&
            tail -f /dev/null"
            #pip install -r requirements.txt && python containerTest.py"

    # GPU allocation - This part was already correct!
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 2
              capabilities: [gpu]
    
    # Optional: Keep these if you need to manually attach to the container
    tty: true
    stdin_open: true

    # Optional: Uncomment this section if your app is a web server
    # ports:
    #   - "8000:8000"
version: "3.8"

services:
  app:
    # Use the official TensorFlow image as the base
    image: tensorflow/tensorflow:2.15.0-gpu
    
    # Give your container a consistent name
    container_name: rt-training
    
    # Mounts the current folder into the /app directory in the container
    volumes:
      - .:/app
      
    # Sets the starting directory inside the container to /app
    working_dir: /app
    # GPU allocation - This part was already correct!
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0', '1']
              capabilities: [gpu]

        # CORRECTED: Combines setup and execution into one command

    
    # Optional: Keep these if you need to manually attach to the container
    tty: true
    stdin_open: true

    # Optional: Uncomment this section if your app is a web server
    ports:
          # Maps port 2222 on your server to port 22 (SSH) in the container
      - "8888:88"
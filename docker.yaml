version: "3.8"

services:
  app:
    # Use the official TensorFlow image as the base
    image: tensorflow/tensorflow:2.13.0-gpu
    
    # Give your container a consistent name
    container_name: my_tf_app
    
    # Mounts the current folder into the /app directory in the container
    volumes:
      - .:/app
      
    # Sets the starting directory inside the container to /app
    working_dir: /app

    # CORRECTED: Combines setup and execution into one command.
    # The container will stay running as long as containerTest.py is running.
    #command: sh -c "
      #pip install gdown &&
        #echo 'Downloading dataset from Google Drive...' &&
        #gdown 'https://drive.google.com/uc?id=1w8T8aMhQjlx75vEjIdTK_zDwJPGzpkgy' -O /app/stacking_blocks.zip &&
        #echo 'Unzipping dataset...' &&
        #unzip /app/stacking_blocks.zip -d /app/stacking_blocks &&
        #rm /app/stacking_blocks.zip &&
        #echo 'Starting application...'&&
        #pip install -r requirements.txt && python containerTest.py&&
        #tail -f /dev/null"

    # GPU allocation - This part was already correct!
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 2
              capabilities: [gpu]
    
    # Optional: Keep these if you need to manually attach to the container
    tty: true
    stdin_open: true

    # Optional: Uncomment this section if your app is a web server
    # ports:
    #   - "8000:8000"